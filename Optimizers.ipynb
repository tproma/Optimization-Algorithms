{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Algorithms\n",
    "Deep learning algorithms require optimizations since training very large deep neural network can be extremely slow. Other than applying a good initialization, batch normalization; a huge boost comes from using a faster optimization algorithm.\n",
    "\n",
    "Here, three optimization algorithms will be presented.\n",
    "- Gradient Descent \n",
    "- Momentum\n",
    "- Adam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Gradient Descent is a primary optimization method in machine learning. \n",
    "For each layer l , the during forward propagation we calculate  W[l] and then during back propagation , we calculate derivatives of that respective weights and biases dW[l] and db[l].\n",
    "\n",
    "For  l=1,...,L , the update is \n",
    "\n",
    "    W[l] = W[l] − α dW[l]\n",
    " \n",
    "    b[l] = b[l] − α db[l]\n",
    " \n",
    "where  α  is the learning rate.\n",
    "All parameters and gradients should be stored in the parameters and gradients dictionary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update(parameters, gradients, learning_rate):\n",
    "\n",
    "    L = len(parameters) \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * gradients['dW' + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * gradients['db' + str(l + 1)]\n",
    "      \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "\n",
    "Momentum takes into account the past gradients to smooth out the update. because the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations. We will store the 'direction' of the previous gradients in the variable  v . Formally, this will be the exponentially weighted average of the gradient on previous steps. \n",
    "\n",
    "<img src = \"GD_M.jpg\">\n",
    "     \n",
    "     \n",
    "Figure: Difference between Gradient Descent and Momentum on mini batches.\n",
    "\n",
    "So, at first, we initialize the velocity v, a python dictionary with arrays of zeros of the same size as of parameters W and b.\n",
    "Then, we implement the parameters update with momentum. The momentum update rule for  l=1,...,L is \n",
    "\n",
    "        vdW[l]=βvdW[l]+(1−β)dW[l]\n",
    "        W[l]=W[l]−αvdW[l]\n",
    " \n",
    "        vdb[l]=βvdb[l]+(1−β)db[l]\n",
    "        b[l]=b[l]−αvdb[l]\n",
    "        \n",
    "Where β is the momentum hyperparameter and  α is the learning rate. All parameters should be stored in the parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    \n",
    "    L = len(parameters) \n",
    "    v = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_update(parameters, gradients, v, beta, learning_rate):\n",
    "\n",
    "    L = len(parameters) \n",
    "\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = beta * v[\"dW\" + str(l+1)] + ( 1- beta)*gradients['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta * v[\"db\" + str(l+1)] + ( 1- beta)*gradients['db' + str(l+1)]\n",
    "       \n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * gradients['dW' + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * gradients['db' + str(l+1)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When β=0, it becomes standard gradient descent without momentum.\n",
    "\n",
    "The larger the momentum  β is, the smoother the update because the more we take the past gradients into account. But if β is too big, it could also smooth out the updates too much.\n",
    "\n",
    "Common values for  β  range from 0.8 to 0.999. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "The most effective optimization algorithms for training neural networks is Adam. It combines ideas from RMSProp (described in lecture) and Momentum. The name Adam is derived from adaptive moment estimation.\n",
    "\n",
    "It calculates an exponentially weighted average of past gradients, and stores it in variables v before bias correction and  vcorrected with bias correction. It then calculates an exponentially weighted average of the squares of the past gradients, and stores it in variables s before bias correction and  scorrected with bias correction.\n",
    "It updates parameters in a direction based on combining information from v and s.\n",
    "The update rule is, for  l=1,...,L\n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "\n",
    "where:\n",
    "t is the number of steps taken of Adam, L is the number of layers, β1 and β2 are hyperparameters that control the two exponentially weighted averages, α is the learning rate, ε  is a very small number to avoid dividing by zero.\n",
    "As usual, we will store all parameters in the parameters dictionary. At first, we initialize the Adam variables v,s which keep track of the past information. The variables v,s are python dictionaries that need to be initialized with arrays of zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "      \n",
    "    L = len(parameters) \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "        s[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        s[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_update(parameters, gradients, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "  \n",
    "    L = len(parameters)              \n",
    "    v_corrected = {}                      \n",
    "    s_corrected = {}                        \n",
    "    \n",
    "    for l in range(L):\n",
    "      \n",
    "        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * gradients['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * gradients['db' + str(l + 1)]\n",
    "      \n",
    "      \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l + 1)] / (1 - beta1**t)\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"dW\" + str(l + 1)] / (1 - beta1**t)\n",
    "      \n",
    "        s[\"dW\" + str(l+1)] =  beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) *gradients['dW' + str(l + 1)]**2\n",
    "        s[\"db\" + str(l+1)] =  beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * gradients['db' + str(l + 1)]**2\n",
    "      \n",
    "\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l + 1)] / (1 - beta2**t)\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"dW\" + str(l + 1)] / (1 - beta2**t)\n",
    "      \n",
    "\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v_corrected[\"dW\" + str(l + 1)] / (np.sqrt(s_corrected[\"dW\" + str(l + 1)]) + epsilon)\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v_corrected[\"db\" + str(l + 1)] / (np.sqrt(s_corrected[\"db\" + str(l + 1)]) + epsilon)\n",
    "       \n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
